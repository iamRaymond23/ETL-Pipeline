# ETL Pipeline | World Bank Datasets
-------------------------------------

This notebook is a part of my learning journey which I've been documenting from data science program, which helped me a lot to learn ETL pipeline.

**ETL stands for Extract, Transform, Load.**

This Analysis uses data from the World Bank. The data comes from two sources:

[World Bank Indicator Data](https://data.worldbank.org/indicator) - This data contains socio-economic indicators for countries around the world. A few example indicators include population, arable land, and central government debt.

[World Bank Project Data](https://datacatalog.worldbank.org/dataset/world-bank-projects-operations) - This data set contains information about World Bank project lending since 1947.

#### Outline of this notebook:

**Extract data from different sources such as:**
- csv files
- SQL Database

**Transform data**
- combining data from different sources
- data cleaning
- data types
- Encodings
- missing data
- duplicate data
- dummy variables
- remove outliers
- scaling features

**Load**
- send the transformed data to a database
- to csv file

**ETL Pipeline**
- code an ETL pipeline

The end goal is to clean these data sets and bring them together into one table. By the end of the notebook, I'll have written an ETL pipeline to extract, transform, and load this data into a new database.

A detailed explanation of each and every step is discussed in the Python notebook.
